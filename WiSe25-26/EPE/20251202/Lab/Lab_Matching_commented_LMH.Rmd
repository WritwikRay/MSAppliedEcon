 ---
title: "Lab Session: Matching"
author: "Cristian Huse"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Converted to R in May/October 2021 using RStudio Version 1.4.1106
```

# Introduction

This lab session is about **Matching**. The structure of the session is as follows:

* Preparation;
  + Load libraries, setwd, load data (.dta format)

* Example 13. Propensity Score Matching (PSM) Estimates
  + Here, we estimate a probit model and compare matched individuals

* PSM using the Nearest-Neighbour Method
  + 1-NN, 2-NN, and 1-NN with logit instead of probit model

* PSM Using Full Matching

Please note that there are different libraries implementing propensity score matching and we selectively cover only one of them.


# Preparation

```{r, echo=F}

##Install packages (I attempted to list all packages needed in the basic lab sessions)
#install.packages("AER")
#install.packages("clubSandwich")
#install.packages("compositions")
#install.packages("fixest")
#install.packages("haven")
#install.packages("MatchIt")
#install.packages("Matching")
#install.packages("modelsummary")
#install.packages("optmatch")
#install.packages("panelr")
#install.packages("plm")
#install.packages("stargazer")
#install.packages("tidyverse")
#install.packages("tidyr")

```

```{r, message=F}
## Initialize ####

rm(list=ls())

#Load libraries
library(AER) #for ivreg
library(fixest) #for feols etc
library(haven) #for read_dta
library(Matching)
library(MatchIt)
library(modelsummary) #for neat tables
library(optmatch)
library(panelr)
library(tidyverse)

```

```{r, echo=F}
## Initialize ####
## Set working directory
#Specify the access path to the computer folder you will use for the analysis
#setwd("INSERT PATH TO PROJECT FOLDER WITH / or \\")  
# Get the directory path of the current R Markdown file
current_rmd <- rstudioapi::getSourceEditorContext()$path

# Set the working directory to the location of the R Markdown file
setwd(dirname(current_rmd))

## open data
#Open the cleaned data set
#set path for data
evaluation <- file.path(getwd(), "Data", "evaluation.dta")
#import .dta file
evaluation.df <- read_dta(evaluation)

```



# Propensity Score Matching (PSM)

Assume we have a group of treated and another of non-treated individuals for which we observe a number of characteristics $X_i$ at baseline, i.e., before the programme is rolled out. One way to quantify treatment effects would be to estimate a model of the form

$$ Y_i = \alpha + \delta P_i + \gamma X_i + \varepsilon_i $$

This strategy would provide a causal estimate for the effect of the program only in very particular cases and might suffer from sample selection, omitted variable bias, and other problems (recall the FTCI). 

Matching parallels the standard regression approach by matching observations in treatment and control groups which are "similar" in terms of characteristics. To the extent that observed characteristics are the drivers of heterogeneity (as opposed to unobserved heterogeneity), matching is a good strategy, being often combined with other quasi-experimental methods such as DD. (Note: Matching per se doesn't ensure causal estimates, but is a way to match to a, say, treated subject, its "closest" non-treated subjects.)

PSM produces a (propensity) score using a regression of programme participation on a set of observed (pre-policy) covariates. Then units in the treatment and comparison group with the closest propensity scores are matched, and differences in outcomes are calculated within each matched pair. The matching
procedure is then repeated for all individuals in the treatment group, and averages in differences in outcomes within pairs are computed. 

There exist different methods to calculate the “closest match” (see slides). 


# Example 13. Propensity Score Matching Estimates

This example illustrates how to implement PSM in the HISP data. First, estimate a probit (alternatively, logit) model where the dependent variable is an indicator of programme participation and the covariates are individual characteristics **pre-programme**. The output of the probit regression shows which variables are the strongest predictors of program participation. 

Before performing any estimation, one needs to **reshape** the data. The intuition is as follows. In the **long format**, each household identifier (the id) appears in two rounds (the waves, 0 and 1), i.e., it is computed as if observed twice (pre- and post-treatment). What we want to match individuals on is on pre-programme characteristics, therefore the reshape operation. Please make sure to have a look at the data before and after reshaping it so you understand what you are doing.

```{r}
#reshape the database
#?panelr::panel_data
# Informs who are i (id) and t (wave)
#?panelr::widen_panel
# Will make round "disappear"
# Note it may take some time for this reshape command to run

eval_wide.df <- panel_data(evaluation.df, id = household_identifier, wave = round) %>%
  widen_panel(separator = "_") %>%
  subset(select = c(-age_hh_1, -age_sp_1, -educ_hh_1, -educ_sp_1, -hospital_1)) %>%
  rename(age_hh = age_hh_0, age_sp = age_sp_0, educ_hh = educ_hh_0, 
         educ_sp = educ_sp_0, hospital = hospital_0)

```


Recall that we are comparing health expenditures at follow-up (post-policy) between treated individuals (enrolled households) and a set of matched non-treated individuals (non-enrolled households) from both treatment and control villages.

The probit estimates highlight the significance of variables such as household size and dwellings with dirt floors in predicting participation in HISP. The propensity score is obtained by computing the predicted values from this first stage. 

```{r}

ex13_glm <- glm(enrolled ~ age_hh + age_sp + educ_hh + educ_sp + female_hh + 
                  indigenous + hhsize + dirtfloor + bathroom + land + 
                  hospital_distance, 
                family = binomial(link = "probit"), 
                data = eval_wide.df)

modelsummary(ex13_glm, 
             vcov = ~ locality_identifier, 
             stars = c("*" = .1, "**" = .05, "***" = .01), 
             fmt = 3, 
             gof_omit = "AIC|BIC|Log.Lik.|R2 Adj.|R2 Within|R2 Pseudo|F")

eval_wide.df$predicted_enrolled <- ex13_glm$fitted.values
```



The following figure plots the propensity scores for the treatment and control groups. Once the propensity scores are calculated, the next step is to find for each individual in the treatment group, a comparable “match” with a similar propensity score in the comparison group, i.e., an individual with characteristics such that its likelihood of participating in the program are the same as the treatment individual for which a match is sought. 

Therefore, matching generally occurs in the area of **common support** where the propensity scores for the treatment and comparison groups overlap. Therefore it is important to check to which extent the **common support assumption** holds empirically.

Once matching is performed, differences in outcomes within pairs are computed and the averages of these differences are obtained to provide estimates of treatment effects. A technical but important note is that matching will typically recover the ATT (Average Treatment Effect on the Treated) instead of the ATE. Intuitively, the ATE would be estimable if one were not to discard observations from the sample or if one were to target full sample balance (dropping observations would go against the idea of a random sample, on which the ATE is intuitively based). Therefore, one should not get surprised with the default option of the type **estimand = "ATT"** in Matching packages.

```{r}
#drop observations omitted in probit estimation, then append fitted values
eval_wide.df <- subset(eval_wide.df, 
                       household_identifier != 
                         subset(eval_wide.df,select=-hospital)
                       [!complete.cases(subset(eval_wide.df, 
                                               select = -hospital)),]$household_identifier) %>%
  mutate(pscore = ex13_glm$fitted.values)

# Density estimates separately for subsamples of enrolled and non-enrolled
  eval_wide_1.df <- subset(eval_wide.df, enrolled == 1)
  eval_wide_0.df <- subset(eval_wide.df, enrolled == 0)
  ex13_density1 <- density(eval_wide_1.df$pscore)
  ex13_density0 <- density(eval_wide_0.df$pscore)

  # Collect x (possibly a grid of values instead of the actual data) and y estimates
  take1 <- ex13_density1$x
  den1 <- ex13_density1$y
  take0 <- ex13_density0$x
  den0 <- ex13_density0$y
 
# Plot
  plot(take0, den0, type = "l", xlim = c(0, 0.8), ylim = c(0, 4), 
       xlab = "Pr(enrolled)", ylab = "density: Pr(enrolled)", 
       lty = 1)
  lines(take1, den1, col = "red", lty = 2)
  legend("topright",
         legend = c("density: Pr(enrolled=0)", "density: Pr(enrolled=1)"), 
         col = c("black", "red"), lty = c(1, 2), )

```



# PSM Using the Package [\textcolor{blue}{MatchIt}](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html)

## [\textcolor{blue}{Checking for Balance}](https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html#check-initial-imbalance)

We start estimating a probit and checking balance. To do so, we specify the "first-stage" equation (**link = "probit"**) and call the library to check balance. The key statistics to focus on are **Std. Mean Diff.**, **Var. Ratio**, and **eCDF**. One should aim for values close to zero for the first and third, and values close to one for the middle one as measures of good balance.

from Grok2: eCDF stands for Empirical Cumulative Distribution Function. Here's a brief explanation:

Definition:
The empirical cumulative distribution function (eCDF) is a statistical tool used to estimate the cumulative distribution function (CDF) of a dataset. For a given dataset, the eCDF at any point gives the proportion of the data points that are less than or equal to x

```{r}
# Notation
Y <- eval_wide.df$health_expenditures_1
Tr <- eval_wide.df$enrolled

# Note: method = NULL 
# ?matchit
m.out0 <- matchit(Tr ~ age_hh + age_sp + educ_hh + educ_sp + female_hh + indigenous +
                    hhsize + dirtfloor + bathroom + land + hospital_distance, 
                  distance = "glm", 
                  link = "probit", 
                  method = NULL, 
                  data = eval_wide.df)

summary(m.out0)

```

## [\textcolor{blue}{Matching Methods}](https://cran.r-project.org/web/packages/MatchIt/vignettes/matching-methods.html)

There is a variety of matching methods, whose technical study is outside the scope of this session. Classical ones include **Nearest Neighbour Matching (method = "nearest")** and **Caliper matching (caliper)**, see link above for discussion and details. Intuitively, NN selects the $K$ observations closest to a given element of the treatment group (K is chosen by the econometrician) whereas caliper matching selects all observations $k$ such that they are within a radius $r$ a given element of the treatment group (formally, $k$ such that $||x_k - x_0|| < r$ for each $x_0$ belonging to the treatment group, $d$ chosen by the econometrician).

In what follows, we first perform the classical 1:1 NN matching method (one element of the control group is assigned to an element of the treatment group) and assess balance. We then specify a regression using the object generated by the **MatchIt** package as input in the next step -- in practice, it carries with it the matched pairs. Note that there are several options available when it comes to matching and that both syntax and output make it conformable with **modelsummary**.

Looking at the diagnostics, extreme propensity scores are more scarce than intermediate ones, as expected. Comparing eQQ plots we get a sense that the matching procedure is doing a reasonably good job, at least for the three selected variables (age_hh, hhsize, hospital_distance) -- observations of treated vs control units are mostly within the confidence bounds. You might want to examine QQ plots of other variables, especially those for which the diagnostics **Std. Mean Diff.**, **Var. Ratio** or **eCDF** raise concerns.

Finally, note that while the estimate doesn't exactly nail the original ones, at $-\$10.02$ their values are pretty close (regard the remark on ATE vs. ATT, which is the estimand used here). 

```{r}

m.out1 <- matchit(Tr ~ age_hh + age_sp + educ_hh + educ_sp + 
                    female_hh + indigenous + hhsize + dirtfloor + 
                    bathroom + land + hospital_distance, 
                  data = eval_wide.df,
                  method = "nearest", distance = "glm", 
                  link = "probit")

m.out1

# Tools for assessing balance
summary(m.out1, un = FALSE)
plot(m.out1, type = "jitter", interactive = FALSE)
plot(m.out1, type = "qq", interactive = FALSE,
     which.xs = c("age_hh", "hhsize", "hospital_distance"))

m.data1 <- match.data(m.out1)

# Specify the regression
fit1 <- lm(health_expenditures_1 ~ enrolled + 
             age_hh + age_sp + educ_hh + educ_sp + 
             female_hh + indigenous + hhsize + dirtfloor +
             bathroom + land + hospital_distance, 
           data = m.data1, 
           weights = weights)

#coeftest(fit1, vcov. = vcovCL, cluster = ~locality_identifier)

model1 <- list("(1) 1-NN" = fit1)

modelsummary(model1,
             vcov = ~ locality_identifier, 
             stars = c("*" = .1, "**" = .05, "***" = .01), 
             fmt = 3, 
             gof_omit = "AIC|BIC|Log.Lik.|R2 Adj.|R2 Within|R2 Pseudo|F")

```

As an alternative, we will adjust the NN-method setting so now two (**ratio = 2**) instead of only one neighbour are selected for each treated observation. (You can check yourself that if you select **ratio = 3**, not every observation will get three neighbours). Note that you can experiment with a number of additional settings which we won't be cover, e.g., **distance**.

When looking at the diagnostics, you will notice that the QQ plots don't necessarily look better than the previous ones for the variables selected. Moreover, at $-\$10.0$, the treatment effect hardly changes when compared to the previous case.

```{r}

m.out2 <- matchit(Tr ~ age_hh + age_sp + educ_hh + educ_sp + 
                    female_hh + indigenous + hhsize + dirtfloor + 
                    bathroom + land + hospital_distance, 
                  data = eval_wide.df,
                  method = "nearest", distance = "glm", 
                  link = "probit", 
                  ratio = 2)

m.out2

# Tools for assessing balance
summary(m.out2, un = FALSE) # if un = TRUE, a matrix of balance statistics for each covariate in the original sample
plot(m.out2, type = "jitter", interactive = FALSE)
plot(m.out2, type = "qq", interactive = FALSE,
     which.xs = c("age_hh", "hhsize", "hospital_distance"))

m.data2 <- match.data(m.out2)

# Specify the regression
fit2 <- lm(health_expenditures_1 ~ enrolled + 
             age_hh + age_sp + educ_hh + educ_sp + 
             female_hh + indigenous + hhsize + dirtfloor +
             bathroom + land + hospital_distance, 
           data = m.data2, 
           weights = weights)

#coeftest(fit2, vcov. = vcovCL, cluster = ~locality_identifier)

model2 <- list("(2) 2-NN" = fit2)

modelsummary(model2,
             vcov = ~ locality_identifier, 
             stars = c("*" = .1, "**" = .05, "***" = .01), 
             fmt = 3, 
             gof_omit = "AIC|BIC|Log.Lik.|R2 Adj.|R2 Within|R2 Pseudo|F")

```

Another moving part when performing matching is the regression model used in the first-stage regression. Therefore, we now investigate what happens when one replaces a probit with a logit model in Specification (1). These models differ when it comes to the underlying distributional assumption, with the probit model assuming a Normal distribution and the logit model assuming a Type-1 extreme value distribution. (We will discuss those models in detail in the future.)

Looking at the results, the estimates are very close when comparing those models ($-10.02$ vs. $-10.18$), which is not uncommon, at least in this specific time of model (binary choice).

```{r}

m.out3 <- matchit(Tr ~ age_hh + age_sp + educ_hh + educ_sp + 
                    female_hh + indigenous + hhsize + dirtfloor + 
                    bathroom + land + hospital_distance, 
                  data = eval_wide.df,
                  method = "nearest", distance = "glm", 
                  link = "logit")

m.out3

# Tools for assessing balance
summary(m.out3, un = FALSE)
plot(m.out3, type = "jitter", interactive = FALSE)
plot(m.out3, type = "qq", interactive = FALSE,
     which.xs = c("age_hh", "hhsize", "hospital_distance"))

m.data3 <- match.data(m.out3)

# Specify the regression
fit3 <- lm(health_expenditures_1 ~ enrolled + 
             age_hh + age_sp + educ_hh + educ_sp + 
             female_hh + indigenous + hhsize + dirtfloor +
             bathroom + land + hospital_distance, 
           data = m.data3, 
           weights = weights)

#coeftest(fit3, vcov. = vcovCL, cluster = ~locality_identifier)

model3 <- list("(3) 1-NN w/ Logit" = fit3)

modelsummary(model3,
             vcov = ~ locality_identifier, 
             stars = c("*" = .1, "**" = .05, "***" = .01), 
             fmt = 3, 
             gof_omit = "AIC|BIC|Log.Lik.|R2 Adj.|R2 Within|R2 Pseudo|F")

```



Finally, we will try a different matching method such as **full matching**, which matches every treated unit to at least one control and every control to at least one treated unit. The treatment effect in this case is lower yet close to previous estimates, at $-\$9.83$. (Please note that this computation can take longer than the previous one.)

All in all, we can say that the programme effects are largely robust to the methods used.


```{r}

m.out4 <- matchit(Tr ~ age_hh + age_sp + educ_hh + educ_sp + 
                    female_hh + indigenous + hhsize + dirtfloor + 
                    bathroom + land + hospital_distance, 
                  data = eval_wide.df,
                  method = "full", distance = "glm", 
                  link = "probit")

m.out4

# Tools for assessing balance
summary(m.out4, un = FALSE)
plot(m.out4, type = "jitter", interactive = FALSE)
plot(m.out4, type = "qq", interactive = FALSE,
     which.xs = c("age_hh", "hhsize", "hospital_distance", "land", "bathroom"))

m.data4 <- match.data(m.out4)

# Specify the regression
fit4 <- lm(health_expenditures_1 ~ enrolled + 
             age_hh + age_sp + educ_hh + educ_sp + 
             female_hh + indigenous + hhsize + dirtfloor +
             bathroom + land + hospital_distance, 
           data = m.data4, 
           weights = weights)

#coeftest(fit3, vcov. = vcovCL, cluster = ~locality_identifier)

model4 <- list("(4) Full Matching" = fit4)

modelsummary(model4,
             vcov = ~ locality_identifier, 
             stars = c("*" = .1, "**" = .05, "***" = .01), 
             fmt = 3, 
             gof_omit = "AIC|BIC|Log.Lik.|R2 Adj.|R2 Within|R2 Pseudo|F")

```

We end by comparing all specifications we estimated in this session. The main result is that the estimates are largely robust across models.

```{r}

modelsummary(c(model1, model2, model3, model4),
             vcov = ~ locality_identifier, 
             stars = c("*" = .1, "**" = .05, "***" = .01), 
             fmt = 3, 
             gof_omit = "AIC|BIC|Log.Lik.|R2 Adj.|R2 Within|R2 Pseudo|F")

```

Answer to the Quizzes
1.	Explain what matching does
Slide 3 in the lecture: 
Good structure to answer this sort of question
Firstly, state the problematic of where we could not observe the counterfactual. Then describe the solution to the problematic (Matching) and how it workts. 
a.	Matching is the statistical technique that is used to find the closest matching group to the treated group based on observable characteristics and measures the effect of the treatment based on these two groups. The reason to do it is because it is impossible to observe the counterfactual. The true counterfactual could only be observed if we could randomly assign treatment and "rewind the clock". The goal of matching techniques is to estimate the missing counterfactual by using the information of subjects from a control group that are "close" to the treated units in some sense. 

2.	Two key assumptions which matching is an appropriate technique to use
a.	Unconfoundedness: the potential outcomes are independent of the assignment of who get the treatment, conditional on the observable covariates.

b.	Overlap: for each value of covariates (characteristics), there is a positive possibility of being in the control or the treatment group. 

3.	When matching would not be appropriate to use
a.	When the data is not extensive enough 
b.	There are not enough characteristics which are observable in order to construct a matching group

answer from slide 50: sMatching is an appropriate method whenever observable characteristics are rich enough to control for treated vs. control group heterogeneity

4. Explain in words what propensity score matching (PSM) does and on which assumption(s) it relies. (slide 7)
	What propensity score matching is the probabilistic approach to find a matching group to the treatment group. It is calculated based on the observable characteristics. It’s a number between 0 and 1 that summarizes the influence of observed characteristics on the likelihood of the enrollment of the program 
o	Also unconfoundedness (this is the correct answer): PS is allowed to be convert to the multidimensional setup of matching into a one-dimensional setup - instead of comparing 10 characteristics, we use the propensity score to do the matching process.


5. Explain why ex post matching is not an appropriate method. (Slide 4 in the lecture)
Key points to note:
The comparison group needs to be as similar as possible to the treatment group, in terms of the observables before the start of the treatment. Using ex post data (observed/collected after start of treatment) is dangerous as it might have been influenced by the treatment itself... The method assumes there are no remaining unobservable differences between treatment and comparison groups i.e., there are not unobservables differently affecting treated and controlled individuals...



# References

Gertler, Paul J.; Martinez, Sebastian; Premand, Patrick; Rawlings, Laura
B.; Vermeersch, Christel M. J. (2016). Impact Evaluation in Practice, Second Edition, Technical Companion (Version 1.0). Washington, DC: Inter-American Development Bank and World Bank.
